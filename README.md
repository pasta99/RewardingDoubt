# Rewarding Doubt 

Code implementation of Rewarding Doubt: A Reinforcement Learning Approach to Confidence Calibration of Large Language Models (https://arxiv.org/abs/2503.02623). 

See the documentation in the single and multiple answer setting folders for usage. 
